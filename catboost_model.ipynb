{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "train = pd.read_csv(\"train2.0.csv\")\n",
    "test_x = pd.read_csv(\"test2.0.csv\")\n",
    "# data = pd.read_csv(\"names.csv\")\n",
    "\n",
    "#set ID as index for train x and y \n",
    "train = train.set_index(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix data type \n",
    "train['gps_height'] = train['gps_height'].astype('float64')\n",
    "train['construction_year'] = train['construction_year'].replace({0:np.nan, 0:np.nan})\n",
    "train['construction_year'] = train['construction_year'].astype('float64')\n",
    "\n",
    "\n",
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create x/y split for trianing \n",
    "train_y = pd.DataFrame(train['status_group'])\n",
    "train_x = train.drop(['status_group'], axis = 1)\n",
    "\n",
    "#save test id and drop \n",
    "test_id = pd.DataFrame(test_x['id'])\n",
    "test_x = test_x.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values for both train and test\n",
    "#needed for the format of catboost\n",
    "train_x.fillna(-999, inplace=True)\n",
    "test_x.fillna(-999,inplace=True)\n",
    "\n",
    "#convert Y to status group to 1,2,3 \n",
    "replace_map = {\"non functional\":3, \n",
    "              \"functional needs repair\":2,\n",
    "              \"functional\":1}\n",
    "\n",
    "train_y['status_group code'] = train_y['status_group'].replace(replace_map)\n",
    "\n",
    "#set data type for non int numbers\n",
    "train_x = train_x.astype({\"amount_tsh\": int})\n",
    "test_x = test_x.astype({\"amount_tsh\": int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "This section of the code is commented out because it takes a long time to run grid search on the amount of data used for the CatBoost model.   \n",
    "\n",
    "After the best parameters were chosen they were added manually to the full model after grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform the dataset\n",
    "# y = train_y['status_group code']\n",
    "\n",
    "# #split data just for testing \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(train_x, y, train_size=0.6, random_state=42)\n",
    "# #Identify cat features for model\n",
    "# categorical_features_indices = np.where(train_x.dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grid search parameters for catboost\n",
    "\n",
    "# params = {'iterations': [1000],\n",
    "#           'learning_rate': [0.01,0.05,.1],\n",
    "#           'depth': [4,6,10],\n",
    "#           'loss_function': ['MultiClass'],\n",
    "#           'logging_level':['Silent'],\n",
    "#           'random_seed': [42],\n",
    "#           'eval_metric' :['AUC']}\n",
    "# clf = CatBoostClassifier()\n",
    "\n",
    "# params = {'depth':[10],\n",
    "#           'iterations':[1000],\n",
    "#           'learning_rate':[0.01,0.05,.1],\n",
    "#             'logging_level':['Silent'],\n",
    "#           'l2_leaf_reg':[10,50],\n",
    "#           'eval_metric' :['AUC']}\n",
    "\n",
    "\n",
    "# scorer = make_scorer(accuracy_score)\n",
    "# clf_grid = GridSearchCV(estimator=clf, param_grid=params, scoring=scorer, cv=10, n_jobs = -1)\n",
    "\n",
    "# clf_grid.fit(X_train, Y_train, cat_features=categorical_features_indices)\n",
    "# best_param = clf_grid.best_params_\n",
    "\n",
    "# # send best param to \n",
    "# pd.DataFrame.from_dict(best_param, orient='index').to_csv('best_param_catboost.csv')\n",
    "# best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing gridsearched parameters \n",
    "# # test model \n",
    "# model_test = CatBoostClassifier(depth = 10, \n",
    "#                                iterations = 1000,\n",
    "#                                learning_rate = .1,\n",
    "#                                l2_leaf_reg = 2,\n",
    "#                                leaf_estimation_iterations = 10,\n",
    "#                                loss_function = 'MultiClass',\n",
    "#                                random_seed = 42,\n",
    "#                                logging_level = 'Silent')\n",
    "                   \n",
    "# model_test.fit(X_train, Y_train ,cat_features=categorical_features_indices)\n",
    "# preds_class_full = model_test.predict(X_test)\n",
    "# accuracy_score(preds_class_full,Y_test)\n",
    "# array = confusion_matrix(preds_class_full,Y_test)\n",
    "# np.asmatrix(array)/(sum(sum(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## caculating feature importance to consifer for feature tunning\n",
    "# importance = pd.DataFrame({'feature_importance': model_test.get_feature_importance(), \n",
    "#               'feature_names': train_x.columns}).sort_values(by=['feature_importance'], \n",
    "#                                                            ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                 int32\n",
       "funder                    object\n",
       "gps_height               float64\n",
       "installer                 object\n",
       "longitude                float64\n",
       "latitude                 float64\n",
       "wpt_name                  object\n",
       "num_private                int64\n",
       "basin                     object\n",
       "subvillage                object\n",
       "region                    object\n",
       "district_code              int64\n",
       "lga                       object\n",
       "ward                      object\n",
       "population                 int64\n",
       "public_meeting              bool\n",
       "scheme_name               object\n",
       "permit                      bool\n",
       "construction_year        float64\n",
       "extraction_type_group     object\n",
       "extraction_type_class     object\n",
       "management                object\n",
       "management_group          object\n",
       "payment                   object\n",
       "quality_group             object\n",
       "quantity                  object\n",
       "source                    object\n",
       "source_type               object\n",
       "source_class              object\n",
       "waterpoint_type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20,\n",
       "       21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full model based on grid search parameters\n",
    "# running full model 9 times on different random seeds to ensemble predictions\n",
    "\n",
    "\n",
    "categorical_features_indices = np.where(train_x.dtypes != np.float)[0]\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Has completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-38ab790ce0e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                    learning_rate = .05)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status_group code'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#Create predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mpreds_class_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_function'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4302\u001b[1;33m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[0;32m   4303\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4304\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1805\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1806\u001b[1;33m             self._train(\n\u001b[0m\u001b[0;32m   1807\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_sets\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = test_id\n",
    "for i in range(9):\n",
    "    #full model    \n",
    "    randomseedx = random.randint(1,10000)\n",
    "    \n",
    "    model_full = CatBoostClassifier(depth = 10, \n",
    "                                   iterations = 1000,\n",
    "                                   loss_function = 'MultiClass',\n",
    "                                   random_seed = randomseedx,\n",
    "                                   logging_level = 'Silent',\n",
    "                                   l2_leaf_reg  = 10,\n",
    "                                   learning_rate = .05)\n",
    "\n",
    "    model_full.fit(train_x, train_y['status_group code'] ,cat_features=categorical_features_indices)\n",
    "    #Create predictions\n",
    "    preds_class_full = pd.DataFrame(model_full.predict(test_x))\n",
    "    names = 'Model ' + str(i+1)\n",
    "    predictions[names] = preds_class_full\n",
    "    print(names + \" Has completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble and fomrating predictions \n",
    "idval = predictions['id']\n",
    "\n",
    "#saving prediction to csv file \n",
    "predictions.to_csv(\"catboost_all_9_models_predictions.csv\", index=False)\n",
    "predicitons = predictions.drop(['id'], axis=1)\n",
    "# ensemble prediction by taking mode of 9 predictions\n",
    "predicitons= predicitons.mode(axis=1)\n",
    "\n",
    "#formating for output \n",
    "submission = pd.concat([idval,predicitons], axis = 1)\n",
    "submission.columns = ['id', 'status_group','error']\n",
    "submission = submission[['id', 'status_group']]\n",
    "\n",
    "#maping labels for contest submission format \n",
    "replace_map2 = {3:\"non functional\", \n",
    "              2:\"functional needs repair\",\n",
    "              1:\"functional\"}\n",
    "submission['status_group'] = submission['status_group'].replace(replace_map2)\n",
    "# exporting submission to csv\n",
    "submission.to_csv(\"submision_catboost.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view submission\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
